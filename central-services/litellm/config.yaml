model_list:
  # OpenAI Models
  - model_name: gpt-4o
    litellm_params:
      model: openai/gpt-4o
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
      input_cost_per_token: 0.000005
      output_cost_per_token: 0.000015
      max_tokens: 128000
      
  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
      input_cost_per_token: 0.00000015
      output_cost_per_token: 0.0000006
      max_tokens: 128000

  - model_name: gpt-3.5-turbo
    litellm_params:
      model: openai/gpt-3.5-turbo
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      mode: chat
      input_cost_per_token: 0.0000005
      output_cost_per_token: 0.0000015
      max_tokens: 16385

  # Anthropic Models
  - model_name: claude-3-5-sonnet
    litellm_params:
      model: anthropic/claude-3-5-sonnet-20241022
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      mode: chat
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015
      max_tokens: 200000

  - model_name: claude-3-haiku
    litellm_params:
      model: anthropic/claude-3-haiku-20240307
      api_key: os.environ/ANTHROPIC_API_KEY
    model_info:
      mode: chat
      input_cost_per_token: 0.00000025
      output_cost_per_token: 0.00000125
      max_tokens: 200000

  # Cohere Models
  - model_name: command-r-plus
    litellm_params:
      model: cohere/command-r-plus
      api_key: os.environ/COHERE_API_KEY
    model_info:
      mode: chat
      input_cost_per_token: 0.000003
      output_cost_per_token: 0.000015
      max_tokens: 128000

  # Azure OpenAI Models
  - model_name: azure-gpt-4o
    litellm_params:
      model: azure/gpt-4o
      api_key: os.environ/AZURE_API_KEY
      api_base: os.environ/AZURE_API_BASE
      api_version: os.environ/AZURE_API_VERSION
    model_info:
      mode: chat
      input_cost_per_token: 0.000005
      output_cost_per_token: 0.000015
      max_tokens: 128000

# General Settings
general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  database_url: os.environ/DATABASE_URL
  
  # Usage tracking and logging
  store_model_in_db: true
  proxy_logging: true
  
  # Rate limiting and quotas
  max_budget: 1000.0  # Default budget per key in USD
  budget_duration: "1mo"  # Budget reset period
  
  # Caching configuration
  redis_host: redis
  redis_port: 6379
  cache_responses: true
  cache_ttl: 3600  # 1 hour cache TTL
  
  # Webhook configuration for usage tracking
  success_callback: ["lago_webhook"]
  failure_callback: ["lago_webhook"]
  
  # Security settings (removed enterprise features)
  # allowed_ips: []  # Enterprise feature
  # blocked_ips: []
  
  # UI settings
  ui_access_mode: "admin_only"
  
# Callback configuration for Lago integration
litellm_settings:
  success_callback: ["lago"]
  failure_callback: ["lago"]
  callback_vars:
    lago_webhook_url: os.environ/LAGO_WEBHOOK_URL
    lago_api_key: os.environ/LAGO_API_KEY

# Router settings for load balancing
router_settings:
  routing_strategy: "least-busy"  # Options: simple-shuffle, least-busy, usage-based-routing
  model_group_alias: {}
  
  # Fallback configuration
  fallbacks: [
    {
      "gpt-4o": ["gpt-4o-mini", "claude-3-5-sonnet"]
    },
    {
      "claude-3-5-sonnet": ["gpt-4o", "command-r-plus"]
    }
  ]

# Team and user management
teams:
  - team_id: "default"
    team_alias: "Default Team"
    members_with_roles:
      - role: "admin"
        user_id: "admin@company.com"
    metadata:
      team_budget: 1000.0
      budget_duration: "1mo"
    models: ["gpt-4o", "gpt-4o-mini", "claude-3-5-sonnet", "claude-3-haiku"]
    
# Environment-specific overrides
environment: "production"  # Options: development, staging, production